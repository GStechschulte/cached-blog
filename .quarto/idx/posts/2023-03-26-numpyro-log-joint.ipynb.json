{"title":"Translating a Model into a Log Joint Probability","markdown":{"yaml":{"aliases":["/probability/inference/jax/2023/03/26/numpyro-log-joint"],"badges":false,"categories":["probability","inference","jax"],"date":"2023-03-26","output-file":"2023-03-26-numpyro-log-joint.html","title":"Translating a Model into a Log Joint Probability","jupyter":"python3","toc":false},"headingText":"Objective","containsRefs":false,"markdown":"\n\n\nIn probabilistic programming languages (PPLs), one needs to compute the joint probability (often unnormalized) of values and observed variables under a generative model to perform approximate inference. However, given a model in the form of a Python function, how does one translate this function (model) into a log joint probability? The objective of this blog is to better understand how modern PPLs, in particular NumPyro, performs this translation in a dynamic way, i.e., the functions for performing this translation can handle a variety of models defined by the user.\n\n## The Model\n\nThe example `zero_inflated_poisson.py` from the NumPyro [docs](https://num.pyro.ai/en/stable/examples/zero_inflated_poisson.html) will be used. In this example, the authors model and predict how many fish are caught by visitors in a state park. Many groups of visitors catch zero fish, either because they did not fish at all or because they were unlucky. They explicitly model this bimodal behavior (zero versus non-zero) and ascertain which variables contribute to each behavior. The authors answer this question by fitting a zero-inflated poisson regression model. We will use NUTs as the inference method to understand the model translation.\n\n### Workflow\n\n1. Define model using NumPyro primitives\n2. Construct a kernel for inference and feed model into kernel\n3. Perform inference using MCMC\n\n## Initializing the kernel\n\nFirst, we initialize the NUTS kernel with the model. The word _kernel_ is used in a wide range of fields ranging from probabilistic programming, statistics, and deep learning. In PPLs, the name kernel is typically used to define the interface with the sampling algorithm. In this case, we have initialized a NUTS kernel with our model, and this kernel will allow us to interface our model with the underlying HMC sampling variant NUTS. \n\nBut, the sampling algorithm can't simply interface with a Python function. Our model, in the form of a Python function, needs to be translated into a joint log density function and used as input into the sampler. Here, this is where NumPyro performs a series of steps to perform this translation.  \n\nWhen we \"feed\" the model into the `NUTS` class an `initialize_model` utility function is called. This function calls various helper functions such as `get_potential_fn` and `find_valid_initial_params` to return a tuple of (`init_params_info`, `potential_fn`, `postprocess_fn`, `model_trace`). Here, we are interested in `initialize_model` and `get_potential_fn`.\n\nThe graph of function calls looks like: initialize model $\\leftrightarrow$ get potential fn $\\leftrightarrow$ potential energy $\\leftrightarrow$ log density where each function being called is also returning an object. Below, the sequential order of functions calls are described.\n\n## initialize_model\n\n`initialize_model` is a function that returns a tuple of objects and values used as input into the HMC algorithm. At a high level, our model and data are passed into the `initialize_model` function to intialize the model to some values using the observed data and `numpyro.sample` statements. This initialization allows us to perform inference with NUTS. Below, the various helper functions that are called within this function are described as these helpers constitute where the majority of our interest lies regarding translating a model into a log joint probability.\n\n## get_potential_fn\n\nInside of `intialize_model`, the function `get_potential_fn` is called. Given a model with Pyro primitives, this Python function returns another function which, given unconstrained parameters, evaluates the potential energy (negative log joint density). In addition, this returns a function to transform unconstrained values at sample sites to constrained values within their respective support. \n\nThe interesting parts here are the _evaluation of potential energy_ and the _returns a function_. First, we focus on the function `potential_energy` to evaluate the potential energy. Later, we then return to the `potential_fn` object.\n\n## potential_energy\n\nComputes potential energy (negative joint log density) of a model given unconstrained parameters. Under the hood, NumPyro will transform these unconstrained parameters to the values belonging to the supports of the corresponding priors in the model. To compute the potential energy, this function calls a `log_density` function that computes the log of joint density for the model given the latent values (parameters).\n\nGiven our NumPyro model, data (model_args), and initialized parameters (using numpyro.sample), the potential energy (negative log joint density) is the following output:\n\n```\n-log_joint: Traced<ConcreteArray([ 15.773586   15.796449   15.68768    17.106882   16.307858   15.10714\n  16.277817   16.401972   17.409088   15.488239   17.44108    20.011204\n  15.796449   16.401972   17.409088   15.488239   32.46398    16.306961\n  18.321064   15.776845   16.432753   41.972443   16.90719    17.324219\n  15.487675   15.68768    15.10714    15.68768    16.96474    61.152782\n  16.319      32.46398    56.631355   16.733091   44.390583   15.796449\n  31.771408   15.9031725  17.999393   15.929144   15.796449   15.776845\n  25.234818   15.487675   32.46398    15.776845   22.136528   16.745249\n  15.796449   15.796449   61.152782   17.459694   15.776845   39.30664\n  31.771408   17.106882   15.796449   15.776845   16.836826   16.90372\n  15.565512   15.266311   15.796449   15.487675   25.503807   66.416145\n  42.01054    15.68768    16.438005   35.528217   16.401972  275.8356\n  15.488239   46.813717   18.31475    42.01054    15.929144   16.733091\n  15.929144   18.632296   16.553946   22.139755   16.879503   16.253452\n  15.929144   16.68712    16.90719    17.409088   16.306961   17.900412\n  72.883484   20.984446   17.080605   15.68768    15.266311   17.459694\n  15.487675   17.409088  221.04407    15.487675   15.68768    15.68768\n  15.903938   17.608683   17.233418   16.945618   17.102604   16.230682\n  16.401972   20.437622   16.307858   15.776845   66.416145   22.85551\n  17.459694   15.266729   18.263693   16.733091   15.68768    16.69443\n  17.767635   16.892221   16.277817   16.699389   15.796449   15.776845\n  15.68768    17.459694   18.93738    16.401972   41.471767   15.796449\n  82.16476    16.664154   15.68768    17.409088   17.106882   15.488239\n  15.266729   17.917303   26.629543   21.383934   18.279554   15.929144\n  16.90719    38.06461    16.673416   15.487675   16.253452   15.776845\n  16.306961   41.61213    15.9031725  15.488239   19.056816   30.152964\n  18.068584   15.796449   15.773586   16.216064   17.080605   16.798647\n  16.733091   16.307858   38.06461    15.487675   16.69443    66.416145\n  16.733091   39.110504   15.266729   15.796449   16.401972   18.379236\n  15.929144   16.276924   15.929144   16.306961  360.43808    15.929144\n  20.011204   15.776845   15.796449   15.487675   39.291206   15.68768\n  15.488239   30.152964   16.879503   15.929144   16.306961   16.69443\n  16.401972   16.553946   15.796449   16.673416   17.080605  379.3062\n  16.745249   17.896193   16.90719    15.266729   15.776845   15.776845 ], \n  dtype=float32)\n```\n\n## log_density\n\nThe `log_density` function first uses the effect handler `substitute` to return a callable which substitutes all primitive calls in `fn` with values from `data` whose key matches the site name. If the site name is not present in `data`, then there is no side effect. After `substitute`, another effect handler `trace` is used to record inputs, distributions, and outputs of `numpyro.sample` statements in the model, and NumPyro primitive calls, generally speaking.\n\nThe effect handlers allow us to effectively loop through each site in the model trace to compute the joint log probability density. In the for loop, if the site `type == sample` grab that sites value(s) (the samples from the numpyro.sample statement) and evaluate the log probability of the value(s) for that sites `fn` (dist.Normal(), dist.MultivariateNormal(), etc.) with `site['fn'].log_prob(<some value>)` The output snippet below shows the site `b1` defined in the model and the `value` sampled using the `numpyro.sample` statement. \n\n```\nsite: {'type': 'sample', 'name': 'b1', 'fn': <numpyro.distributions.distribution.Independent object at 0x13a9ceb20>, 'args': (), 'kwargs': {'rng_key': None, 'sample_shape': ()}, 'value': Traced<ConcreteArray([ 1.2406311  -0.5222316  -1.2795658   1.800642   -0.43796206], dtype=float32)>with<JVPTrace(level=2/0)> with\n  primal = Array([ 1.2406311 , -0.5222316 , -1.2795658 ,  1.800642  , -0.43796206],      dtype=float32)\n  tangent = Traced<ShapedArray(float32[5])>with<JaxprTrace(level=1/0)> with\n    pval = (ShapedArray(float32[5]), None)\n    recipe = LambdaBinding(), 'scale': None, 'is_observed': False, 'intermediates': [], 'cond_indep_stack': [], 'infer': {}} \n\nvalue: Traced<ConcreteArray([ 1.2406311  -0.5222316  -1.2795658   1.800642   -0.43796206], dtype=float32)>with<JVPTrace(level=2/0)> with\n  primal = Array([ 1.2406311 , -0.5222316 , -1.2795658 ,  1.800642  , -0.43796206],      dtype=float32)\n  tangent = Traced<ShapedArray(float32[5])>with<JaxprTrace(level=1/0)> with\n    pval = (ShapedArray(float32[5]), None)\n    recipe = LambdaBinding(), \n```\n\nSubsequently, we can also see the `fn` of this sample site defined in our model:\n\n```\nsite fn: <numpyro.distributions.distribution.Independent object at 0x13a9ceb20>\n```\n\nwhere the `fn` is an `Independent` Normal distribution because we called the `.to_event(1)` method in our model. Next, the log probability for the sample site value is computed by calling the `.log_prob()` method. For example, the log probability of the sampled values for site `b1` is:\n\n```\nlog prob.    = Traced<ConcreteArray(-8.036343574523926, dtype=float32)\n```\n\nSubsequently, we sum over the log probability for that site. Lastly, the variable `log_joint` is created for the log joint probability density, and the current site log probability is added to the log joint probability. After looping through each sample site, the log joint then represents the log joint probability density for the model given the latent values (parameters). \n\n```\nlog joint         = Traced<ConcreteArray([ -15.773586   -15.796449   -15.68768    -17.106882   -16.307858\n  -15.10714    -16.277817   -16.401972   -17.409088   -15.488239\n  -17.44108    -20.011204   -15.796449   -16.401972   -17.409088\n  -15.488239   -32.46398    -16.306961   -18.321064   -15.776845\n  -16.432753   -41.972443   -16.90719    -17.324219   -15.487675\n  -15.68768    -15.10714    -15.68768    -16.96474    -61.152782\n  -16.319      -32.46398    -56.631355   -16.733091   -44.390583\n  -15.796449   -31.771408   -15.9031725  -17.999393   -15.929144\n  -15.796449   -15.776845   -25.234818   -15.487675   -32.46398\n  -15.776845   -22.136528   -16.745249   -15.796449   -15.796449\n  -61.152782   -17.459694   -15.776845   -39.30664    -31.771408\n  -17.106882   -15.796449   -15.776845   -16.836826   -16.90372\n  -15.565512   -15.266311   -15.796449   -15.487675   -25.503807\n  -66.416145   -42.01054    -15.68768    -16.438005   -35.528217\n  -16.401972  -275.8356     -15.488239   -46.813717   -18.31475\n  -42.01054    -15.929144   -16.733091   -15.929144   -18.632296\n  -16.553946   -22.139755   -16.879503   -16.253452   -15.929144\n  -16.68712    -16.90719    -17.409088   -16.306961   -17.900412\n  -72.883484   -20.984446   -17.080605   -15.68768    -15.266311\n  -17.459694   -15.487675   -17.409088  -221.04407    -15.487675\n  -15.68768    -15.68768    -15.903938   -17.608683   -17.233418\n  -16.945618   -17.102604   -16.230682   -16.401972   -20.437622\n  -16.307858   -15.776845   -66.416145   -22.85551    -17.459694\n  -15.266729   -18.263693   -16.733091   -15.68768    -16.69443\n  -17.767635   -16.892221   -16.277817   -16.699389   -15.796449\n  -15.776845   -15.68768    -17.459694   -18.93738    -16.401972\n  -41.471767   -15.796449   -82.16476    -16.664154   -15.68768\n  -17.409088   -17.106882   -15.488239   -15.266729   -17.917303\n  -26.629543   -21.383934   -18.279554   -15.929144   -16.90719\n  -38.06461    -16.673416   -15.487675   -16.253452   -15.776845\n  -16.306961   -41.61213    -15.9031725  -15.488239   -19.056816\n  -30.152964   -18.068584   -15.796449   -15.773586   -16.216064\n  -17.080605   -16.798647   -16.733091   -16.307858   -38.06461\n  -15.487675   -16.69443    -66.416145   -16.733091   -39.110504\n  -15.266729   -15.796449   -16.401972   -18.379236   -15.929144\n  -16.276924   -15.929144   -16.306961  -360.43808    -15.929144\n  -20.011204   -15.776845   -15.796449   -15.487675   -39.291206\n  -15.68768    -15.488239   -30.152964   -16.879503   -15.929144\n  -16.306961   -16.69443    -16.401972   -16.553946   -15.796449\n  -16.673416   -17.080605  -379.3062     -16.745249   -17.896193\n  -16.90719    -15.266729   -15.776845   -15.776845 ], dtype=float32)\n```\n\nAnd voila, this output is the log joint probability density (and placing a negative sign in front of this array gives you the potential energy) for the model given the latent values. The values in the output above represent the log joint probability of the initialized latent valus, i.e., no inference has been ran yet. \n\n## Returning to get_potential_fn\n\nHowever, `log_density` and `potential_energy` compute the log probability of the current latent value, not a **function**. Therefore, we return to the Python function `get_potential_fn` that returns the log joint probability as a function `potential_fn`, i.e., a function that will evaluate the potential energy given the model args defined by our `model`, i.e., `X_train` and `y_train` and the latent values using the `log_density` function described above. The `potential_fn` is then \"fed\" into the HMC algorithm to perform inference.\n\nWhat's great about `get_potential_fn` is that the log joint probability density function can be accessed externally given our NumPyro model, and passed into other sampling libraries such as [Blackjax](https://blackjax-devs.github.io/blackjax/examples/howto_use_numpyro.html).\n\n# Summary\n\nTo translate a NumPyro model, in the form of a Python function, to a joint probability (function and value) a series of function calls are performed. Namely, initialize model $\\leftrightarrow$ get potential fn $\\leftrightarrow$ potential energy $\\leftrightarrow$ log density. \n\n- `log_density` computes the log probability of the current latent (parameter) value and observed data\n- `potential_energy` is `-log_density`\n- `get_potential_fn` returns the log joint probability as a function `potential_fn`, i.e., a function that will evaluate the potential energy given the model args defined by our `model`, i.e., `X_train` and `y_train` and the latent values using the `log_density` function. The `potential_fn` is then \"fed\" into the HMC algorithm to perform inference.\n\nThis process allows users to (1) translate their models in a dynamic manner, and (2) access the log joint probability for external use, such as in Blackjax.\n","srcMarkdownNoYaml":"\n\n## Objective\n\nIn probabilistic programming languages (PPLs), one needs to compute the joint probability (often unnormalized) of values and observed variables under a generative model to perform approximate inference. However, given a model in the form of a Python function, how does one translate this function (model) into a log joint probability? The objective of this blog is to better understand how modern PPLs, in particular NumPyro, performs this translation in a dynamic way, i.e., the functions for performing this translation can handle a variety of models defined by the user.\n\n## The Model\n\nThe example `zero_inflated_poisson.py` from the NumPyro [docs](https://num.pyro.ai/en/stable/examples/zero_inflated_poisson.html) will be used. In this example, the authors model and predict how many fish are caught by visitors in a state park. Many groups of visitors catch zero fish, either because they did not fish at all or because they were unlucky. They explicitly model this bimodal behavior (zero versus non-zero) and ascertain which variables contribute to each behavior. The authors answer this question by fitting a zero-inflated poisson regression model. We will use NUTs as the inference method to understand the model translation.\n\n### Workflow\n\n1. Define model using NumPyro primitives\n2. Construct a kernel for inference and feed model into kernel\n3. Perform inference using MCMC\n\n## Initializing the kernel\n\nFirst, we initialize the NUTS kernel with the model. The word _kernel_ is used in a wide range of fields ranging from probabilistic programming, statistics, and deep learning. In PPLs, the name kernel is typically used to define the interface with the sampling algorithm. In this case, we have initialized a NUTS kernel with our model, and this kernel will allow us to interface our model with the underlying HMC sampling variant NUTS. \n\nBut, the sampling algorithm can't simply interface with a Python function. Our model, in the form of a Python function, needs to be translated into a joint log density function and used as input into the sampler. Here, this is where NumPyro performs a series of steps to perform this translation.  \n\nWhen we \"feed\" the model into the `NUTS` class an `initialize_model` utility function is called. This function calls various helper functions such as `get_potential_fn` and `find_valid_initial_params` to return a tuple of (`init_params_info`, `potential_fn`, `postprocess_fn`, `model_trace`). Here, we are interested in `initialize_model` and `get_potential_fn`.\n\nThe graph of function calls looks like: initialize model $\\leftrightarrow$ get potential fn $\\leftrightarrow$ potential energy $\\leftrightarrow$ log density where each function being called is also returning an object. Below, the sequential order of functions calls are described.\n\n## initialize_model\n\n`initialize_model` is a function that returns a tuple of objects and values used as input into the HMC algorithm. At a high level, our model and data are passed into the `initialize_model` function to intialize the model to some values using the observed data and `numpyro.sample` statements. This initialization allows us to perform inference with NUTS. Below, the various helper functions that are called within this function are described as these helpers constitute where the majority of our interest lies regarding translating a model into a log joint probability.\n\n## get_potential_fn\n\nInside of `intialize_model`, the function `get_potential_fn` is called. Given a model with Pyro primitives, this Python function returns another function which, given unconstrained parameters, evaluates the potential energy (negative log joint density). In addition, this returns a function to transform unconstrained values at sample sites to constrained values within their respective support. \n\nThe interesting parts here are the _evaluation of potential energy_ and the _returns a function_. First, we focus on the function `potential_energy` to evaluate the potential energy. Later, we then return to the `potential_fn` object.\n\n## potential_energy\n\nComputes potential energy (negative joint log density) of a model given unconstrained parameters. Under the hood, NumPyro will transform these unconstrained parameters to the values belonging to the supports of the corresponding priors in the model. To compute the potential energy, this function calls a `log_density` function that computes the log of joint density for the model given the latent values (parameters).\n\nGiven our NumPyro model, data (model_args), and initialized parameters (using numpyro.sample), the potential energy (negative log joint density) is the following output:\n\n```\n-log_joint: Traced<ConcreteArray([ 15.773586   15.796449   15.68768    17.106882   16.307858   15.10714\n  16.277817   16.401972   17.409088   15.488239   17.44108    20.011204\n  15.796449   16.401972   17.409088   15.488239   32.46398    16.306961\n  18.321064   15.776845   16.432753   41.972443   16.90719    17.324219\n  15.487675   15.68768    15.10714    15.68768    16.96474    61.152782\n  16.319      32.46398    56.631355   16.733091   44.390583   15.796449\n  31.771408   15.9031725  17.999393   15.929144   15.796449   15.776845\n  25.234818   15.487675   32.46398    15.776845   22.136528   16.745249\n  15.796449   15.796449   61.152782   17.459694   15.776845   39.30664\n  31.771408   17.106882   15.796449   15.776845   16.836826   16.90372\n  15.565512   15.266311   15.796449   15.487675   25.503807   66.416145\n  42.01054    15.68768    16.438005   35.528217   16.401972  275.8356\n  15.488239   46.813717   18.31475    42.01054    15.929144   16.733091\n  15.929144   18.632296   16.553946   22.139755   16.879503   16.253452\n  15.929144   16.68712    16.90719    17.409088   16.306961   17.900412\n  72.883484   20.984446   17.080605   15.68768    15.266311   17.459694\n  15.487675   17.409088  221.04407    15.487675   15.68768    15.68768\n  15.903938   17.608683   17.233418   16.945618   17.102604   16.230682\n  16.401972   20.437622   16.307858   15.776845   66.416145   22.85551\n  17.459694   15.266729   18.263693   16.733091   15.68768    16.69443\n  17.767635   16.892221   16.277817   16.699389   15.796449   15.776845\n  15.68768    17.459694   18.93738    16.401972   41.471767   15.796449\n  82.16476    16.664154   15.68768    17.409088   17.106882   15.488239\n  15.266729   17.917303   26.629543   21.383934   18.279554   15.929144\n  16.90719    38.06461    16.673416   15.487675   16.253452   15.776845\n  16.306961   41.61213    15.9031725  15.488239   19.056816   30.152964\n  18.068584   15.796449   15.773586   16.216064   17.080605   16.798647\n  16.733091   16.307858   38.06461    15.487675   16.69443    66.416145\n  16.733091   39.110504   15.266729   15.796449   16.401972   18.379236\n  15.929144   16.276924   15.929144   16.306961  360.43808    15.929144\n  20.011204   15.776845   15.796449   15.487675   39.291206   15.68768\n  15.488239   30.152964   16.879503   15.929144   16.306961   16.69443\n  16.401972   16.553946   15.796449   16.673416   17.080605  379.3062\n  16.745249   17.896193   16.90719    15.266729   15.776845   15.776845 ], \n  dtype=float32)\n```\n\n## log_density\n\nThe `log_density` function first uses the effect handler `substitute` to return a callable which substitutes all primitive calls in `fn` with values from `data` whose key matches the site name. If the site name is not present in `data`, then there is no side effect. After `substitute`, another effect handler `trace` is used to record inputs, distributions, and outputs of `numpyro.sample` statements in the model, and NumPyro primitive calls, generally speaking.\n\nThe effect handlers allow us to effectively loop through each site in the model trace to compute the joint log probability density. In the for loop, if the site `type == sample` grab that sites value(s) (the samples from the numpyro.sample statement) and evaluate the log probability of the value(s) for that sites `fn` (dist.Normal(), dist.MultivariateNormal(), etc.) with `site['fn'].log_prob(<some value>)` The output snippet below shows the site `b1` defined in the model and the `value` sampled using the `numpyro.sample` statement. \n\n```\nsite: {'type': 'sample', 'name': 'b1', 'fn': <numpyro.distributions.distribution.Independent object at 0x13a9ceb20>, 'args': (), 'kwargs': {'rng_key': None, 'sample_shape': ()}, 'value': Traced<ConcreteArray([ 1.2406311  -0.5222316  -1.2795658   1.800642   -0.43796206], dtype=float32)>with<JVPTrace(level=2/0)> with\n  primal = Array([ 1.2406311 , -0.5222316 , -1.2795658 ,  1.800642  , -0.43796206],      dtype=float32)\n  tangent = Traced<ShapedArray(float32[5])>with<JaxprTrace(level=1/0)> with\n    pval = (ShapedArray(float32[5]), None)\n    recipe = LambdaBinding(), 'scale': None, 'is_observed': False, 'intermediates': [], 'cond_indep_stack': [], 'infer': {}} \n\nvalue: Traced<ConcreteArray([ 1.2406311  -0.5222316  -1.2795658   1.800642   -0.43796206], dtype=float32)>with<JVPTrace(level=2/0)> with\n  primal = Array([ 1.2406311 , -0.5222316 , -1.2795658 ,  1.800642  , -0.43796206],      dtype=float32)\n  tangent = Traced<ShapedArray(float32[5])>with<JaxprTrace(level=1/0)> with\n    pval = (ShapedArray(float32[5]), None)\n    recipe = LambdaBinding(), \n```\n\nSubsequently, we can also see the `fn` of this sample site defined in our model:\n\n```\nsite fn: <numpyro.distributions.distribution.Independent object at 0x13a9ceb20>\n```\n\nwhere the `fn` is an `Independent` Normal distribution because we called the `.to_event(1)` method in our model. Next, the log probability for the sample site value is computed by calling the `.log_prob()` method. For example, the log probability of the sampled values for site `b1` is:\n\n```\nlog prob.    = Traced<ConcreteArray(-8.036343574523926, dtype=float32)\n```\n\nSubsequently, we sum over the log probability for that site. Lastly, the variable `log_joint` is created for the log joint probability density, and the current site log probability is added to the log joint probability. After looping through each sample site, the log joint then represents the log joint probability density for the model given the latent values (parameters). \n\n```\nlog joint         = Traced<ConcreteArray([ -15.773586   -15.796449   -15.68768    -17.106882   -16.307858\n  -15.10714    -16.277817   -16.401972   -17.409088   -15.488239\n  -17.44108    -20.011204   -15.796449   -16.401972   -17.409088\n  -15.488239   -32.46398    -16.306961   -18.321064   -15.776845\n  -16.432753   -41.972443   -16.90719    -17.324219   -15.487675\n  -15.68768    -15.10714    -15.68768    -16.96474    -61.152782\n  -16.319      -32.46398    -56.631355   -16.733091   -44.390583\n  -15.796449   -31.771408   -15.9031725  -17.999393   -15.929144\n  -15.796449   -15.776845   -25.234818   -15.487675   -32.46398\n  -15.776845   -22.136528   -16.745249   -15.796449   -15.796449\n  -61.152782   -17.459694   -15.776845   -39.30664    -31.771408\n  -17.106882   -15.796449   -15.776845   -16.836826   -16.90372\n  -15.565512   -15.266311   -15.796449   -15.487675   -25.503807\n  -66.416145   -42.01054    -15.68768    -16.438005   -35.528217\n  -16.401972  -275.8356     -15.488239   -46.813717   -18.31475\n  -42.01054    -15.929144   -16.733091   -15.929144   -18.632296\n  -16.553946   -22.139755   -16.879503   -16.253452   -15.929144\n  -16.68712    -16.90719    -17.409088   -16.306961   -17.900412\n  -72.883484   -20.984446   -17.080605   -15.68768    -15.266311\n  -17.459694   -15.487675   -17.409088  -221.04407    -15.487675\n  -15.68768    -15.68768    -15.903938   -17.608683   -17.233418\n  -16.945618   -17.102604   -16.230682   -16.401972   -20.437622\n  -16.307858   -15.776845   -66.416145   -22.85551    -17.459694\n  -15.266729   -18.263693   -16.733091   -15.68768    -16.69443\n  -17.767635   -16.892221   -16.277817   -16.699389   -15.796449\n  -15.776845   -15.68768    -17.459694   -18.93738    -16.401972\n  -41.471767   -15.796449   -82.16476    -16.664154   -15.68768\n  -17.409088   -17.106882   -15.488239   -15.266729   -17.917303\n  -26.629543   -21.383934   -18.279554   -15.929144   -16.90719\n  -38.06461    -16.673416   -15.487675   -16.253452   -15.776845\n  -16.306961   -41.61213    -15.9031725  -15.488239   -19.056816\n  -30.152964   -18.068584   -15.796449   -15.773586   -16.216064\n  -17.080605   -16.798647   -16.733091   -16.307858   -38.06461\n  -15.487675   -16.69443    -66.416145   -16.733091   -39.110504\n  -15.266729   -15.796449   -16.401972   -18.379236   -15.929144\n  -16.276924   -15.929144   -16.306961  -360.43808    -15.929144\n  -20.011204   -15.776845   -15.796449   -15.487675   -39.291206\n  -15.68768    -15.488239   -30.152964   -16.879503   -15.929144\n  -16.306961   -16.69443    -16.401972   -16.553946   -15.796449\n  -16.673416   -17.080605  -379.3062     -16.745249   -17.896193\n  -16.90719    -15.266729   -15.776845   -15.776845 ], dtype=float32)\n```\n\nAnd voila, this output is the log joint probability density (and placing a negative sign in front of this array gives you the potential energy) for the model given the latent values. The values in the output above represent the log joint probability of the initialized latent valus, i.e., no inference has been ran yet. \n\n## Returning to get_potential_fn\n\nHowever, `log_density` and `potential_energy` compute the log probability of the current latent value, not a **function**. Therefore, we return to the Python function `get_potential_fn` that returns the log joint probability as a function `potential_fn`, i.e., a function that will evaluate the potential energy given the model args defined by our `model`, i.e., `X_train` and `y_train` and the latent values using the `log_density` function described above. The `potential_fn` is then \"fed\" into the HMC algorithm to perform inference.\n\nWhat's great about `get_potential_fn` is that the log joint probability density function can be accessed externally given our NumPyro model, and passed into other sampling libraries such as [Blackjax](https://blackjax-devs.github.io/blackjax/examples/howto_use_numpyro.html).\n\n# Summary\n\nTo translate a NumPyro model, in the form of a Python function, to a joint probability (function and value) a series of function calls are performed. Namely, initialize model $\\leftrightarrow$ get potential fn $\\leftrightarrow$ potential energy $\\leftrightarrow$ log density. \n\n- `log_density` computes the log probability of the current latent (parameter) value and observed data\n- `potential_energy` is `-log_density`\n- `get_potential_fn` returns the log joint probability as a function `potential_fn`, i.e., a function that will evaluate the potential energy given the model args defined by our `model`, i.e., `X_train` and `y_train` and the latent values using the `log_density` function. The `potential_fn` is then \"fed\" into the HMC algorithm to perform inference.\n\nThis process allows users to (1) translate their models in a dynamic manner, and (2) access the log joint probability for external use, such as in Blackjax.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"output-file":"2023-03-26-numpyro-log-joint.html","toc":false},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.306","theme":"cosmo","title-block-banner":true,"aliases":["/probability/inference/jax/2023/03/26/numpyro-log-joint"],"badges":false,"categories":["probability","inference","jax"],"date":"2023-03-26","title":"Translating a Model into a Log Joint Probability","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}
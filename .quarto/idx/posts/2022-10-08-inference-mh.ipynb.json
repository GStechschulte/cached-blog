{"title":"Inference - Metropolis Hastings from Scratch","markdown":{"yaml":{"aliases":["/probability/sampling/inference/pytorch/2022/10/08/inference-mh"],"badges":false,"categories":["probability","sampling","inference","pytorch"],"date":"2022-10-08","output-file":"2022-10-08-inference-mh.html","title":"Inference - Metropolis Hastings from Scratch","toc":false},"headingText":"Main Idea","containsRefs":false,"markdown":"\n\n\n\n\nMetropolis-Hastings (MH) is one of the simplest kinds of MCMC algorithms. The idea with MH is that at each step, we propose to move from the current state $x$ to a new state $x'$ with probability $q(x'|x)$, where $q$ is the **proposal distribution**. The user is free to choose the proposal distribution and the choice of the proposal is dependent on the form of the target distribution. Once a proposal has been made to move to $x'$, we then decide whether to **accept** or **reject** the proposal according to some rule. If the proposal is accepted, the new state is $x'$, else the new state is the same as the current state $x$. \n\nProposals can be **symmetric** and **asymmetric**. In the case of symmetric proposals $q(x'|x) = q(x|x')$, the acceptance probability is given by the rule:\n\n$$A = min(1, \\frac{p^*(x')}{p^*(x)})$$\n\nThe fraction is a ratio between the probabilities of the proposed state $x'$ and current state $x$. If $x'$ is more probable than $x$, the ratio is $> 1$, and we move to the proposed state. However, if $x'$ is less probable, we may still move there, depending on the relative probabilities. If the relative probabilities are similar, we may code _exploration_ into the algorithm such that they go in the opposite direction. This helps with the greediness of the original algorithm—only moving to more probable states. \n\n### The Algorithm\n\n1. Initialize $x^0$\n\n2. for $s = 0, 1, 2, 3, ...$ do:\n   - Define $x = x^s$\n   - Sample $x' \\sim q(x'|x)$ where $q$ is the user's proposal distribution\n   - Compute the acceptance probability given by:\n   - $p_a(x_{t+1}|x_i) = min(1, \\frac{p(x_{i+1})q(x_i | x_{i+1})}{p(x_i)q(x_{i+1}|x_I)})$\n\n3. Compute $A = min(1, \\alpha)$\n\n4. Sample $u \\sim U(0, 1)$\n\n5. Set new sample to:\n$x^{s+1} = \n\\left\\{\n\\begin{array}{ll}\n    x' & \\quad \\text{if} \\quad u \\leq A(\\text{accept}) \\\\\n    x & \\quad \\text{if} \\quad x > A(\\text{reject}) \\\\\n\\end{array}\n\\right.$\n\n\n### Random Walk Metropolis-Hastings\n\nThe random walk metropolis-hastings (RWMH) corresponds to MH with a Gaussian propsal distribution of the form:\n\n$$q(x'|x) = \\mathcal{N}(x'|x, \\tau^2 I)$$\n\nBelow, I implement the RWMH for sampling from a 1-dimenensional mixture of Gaussians (implemented using the `MixtureSameFamily` PyTorch class) with the following parameters:\n\n- $\\mu = -20, 20$\n- Mixture component probability $= 0.3, 0.7$\n- $\\sum = 10, 10$\n\n\n### Results\n\nThe mixture distribution can be tricky to sample from as it is has more than one model, i.e., it is a bimodal distribution. However, we can see that the RWMH spends time sampling from both component distributions, albeit, the distribution with the higher probability more. Due to the random search based perturbations (random walk), the sampler seems to randomly jump from component to component, showing that the chain is not _sticky_. Additionally, the acceptance rate is $0.803$ indicating that about $80\\%$ of new proposals were accepted.\n","srcMarkdownNoYaml":"\n\n\n\n### Main Idea\n\nMetropolis-Hastings (MH) is one of the simplest kinds of MCMC algorithms. The idea with MH is that at each step, we propose to move from the current state $x$ to a new state $x'$ with probability $q(x'|x)$, where $q$ is the **proposal distribution**. The user is free to choose the proposal distribution and the choice of the proposal is dependent on the form of the target distribution. Once a proposal has been made to move to $x'$, we then decide whether to **accept** or **reject** the proposal according to some rule. If the proposal is accepted, the new state is $x'$, else the new state is the same as the current state $x$. \n\nProposals can be **symmetric** and **asymmetric**. In the case of symmetric proposals $q(x'|x) = q(x|x')$, the acceptance probability is given by the rule:\n\n$$A = min(1, \\frac{p^*(x')}{p^*(x)})$$\n\nThe fraction is a ratio between the probabilities of the proposed state $x'$ and current state $x$. If $x'$ is more probable than $x$, the ratio is $> 1$, and we move to the proposed state. However, if $x'$ is less probable, we may still move there, depending on the relative probabilities. If the relative probabilities are similar, we may code _exploration_ into the algorithm such that they go in the opposite direction. This helps with the greediness of the original algorithm—only moving to more probable states. \n\n### The Algorithm\n\n1. Initialize $x^0$\n\n2. for $s = 0, 1, 2, 3, ...$ do:\n   - Define $x = x^s$\n   - Sample $x' \\sim q(x'|x)$ where $q$ is the user's proposal distribution\n   - Compute the acceptance probability given by:\n   - $p_a(x_{t+1}|x_i) = min(1, \\frac{p(x_{i+1})q(x_i | x_{i+1})}{p(x_i)q(x_{i+1}|x_I)})$\n\n3. Compute $A = min(1, \\alpha)$\n\n4. Sample $u \\sim U(0, 1)$\n\n5. Set new sample to:\n$x^{s+1} = \n\\left\\{\n\\begin{array}{ll}\n    x' & \\quad \\text{if} \\quad u \\leq A(\\text{accept}) \\\\\n    x & \\quad \\text{if} \\quad x > A(\\text{reject}) \\\\\n\\end{array}\n\\right.$\n\n\n### Random Walk Metropolis-Hastings\n\nThe random walk metropolis-hastings (RWMH) corresponds to MH with a Gaussian propsal distribution of the form:\n\n$$q(x'|x) = \\mathcal{N}(x'|x, \\tau^2 I)$$\n\nBelow, I implement the RWMH for sampling from a 1-dimenensional mixture of Gaussians (implemented using the `MixtureSameFamily` PyTorch class) with the following parameters:\n\n- $\\mu = -20, 20$\n- Mixture component probability $= 0.3, 0.7$\n- $\\sum = 10, 10$\n\n\n### Results\n\nThe mixture distribution can be tricky to sample from as it is has more than one model, i.e., it is a bimodal distribution. However, we can see that the RWMH spends time sampling from both component distributions, albeit, the distribution with the higher probability more. Due to the random search based perturbations (random walk), the sampler seems to randomly jump from component to component, showing that the chain is not _sticky_. Additionally, the acceptance rate is $0.803$ indicating that about $80\\%$ of new proposals were accepted.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"output-file":"2022-10-08-inference-mh.html","toc":false},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.306","theme":"cosmo","title-block-banner":true,"aliases":["/probability/sampling/inference/pytorch/2022/10/08/inference-mh"],"badges":false,"categories":["probability","sampling","inference","pytorch"],"date":"2022-10-08","title":"Inference - Metropolis Hastings from Scratch"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}